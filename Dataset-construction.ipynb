{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cc2417-4002-4769-98b8-7c60d7e8c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import netrep.metrics as met\n",
    "from typing import Literal, Tuple, Optional, List\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "433b59f9-825e-4bab-a535-11b48c14266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3739b3a4-01ea-4a51-9b20-8e642ced3d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events(file,event_duration):\n",
    "    events=mne.events_from_annotations(file)\n",
    "    epochs = mne.Epochs(file,events[0],events[1],tmin=-0.001, tmax=event_duration,event_repeated=\"drop\",preload=True, picks=file.ch_names[:-2])\n",
    "    epochs_scaled=mne.decoding.Scaler(epochs.info).fit_transform(epochs.get_data())\n",
    "    \n",
    "    signal_by_stim={}\n",
    "    stimulus_ids=epochs.event_id\n",
    "    \n",
    "    for stim_id, stim_code in stimulus_ids.items():\n",
    "        stim_events=epochs_scaled[epochs.events[:,2]==stim_code]\n",
    "    \n",
    "        signal_by_stim[stim_id]=stim_events\n",
    "    \n",
    "    return signal_by_stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a8ae91b-74c3-4cb4-b4b3-7ba06d65203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_samples(x):\n",
    "    dims_count=len(x.shape)\n",
    "    return x.reshape(*x.shape[:-(dims_count-1)], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b8b941-540f-40f2-b487-f0b84665c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_cov(x):\n",
    "    new_x=flatten_samples(x)\n",
    "    \n",
    "    mu=np.mean(new_x, axis=0)\n",
    "    cov=np.cov(new_x, rowvar=False)\n",
    "    \n",
    "    return np.expand_dims(mu,0),np.expand_dims(cov,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c130ef0-a407-40ae-99b8-9b01a512d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_per_person(folder, aggregate=lambda x: np.mean(x, axis=0)):\n",
    "    per_session_avg_s16=[]\n",
    "    per_session_avg_s32=[]\n",
    "    for i in [1,2,3]:\n",
    "        file=mne.io.read_raw_brainvision(f\"neuro/{folder}/gonogo{i}.vhdr\")\n",
    "        events=get_events(file, 0.5)\n",
    "        s16=events[\"Stimulus/S 16\"]\n",
    "        s32=events[\"Stimulus/S 32\"]\n",
    "        if aggregate:\n",
    "            per_session_avg_s16.append(aggregate(s16))\n",
    "            per_session_avg_s32.append(aggregate(s32))\n",
    "        else:\n",
    "            per_session_avg_s16.append(s16)\n",
    "            per_session_avg_s32.append(s32)\n",
    "        \n",
    "\n",
    "    return np.array(per_session_avg_s16), np.array(per_session_avg_s32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe76ab7c-002e-424b-b345-719b3b0c3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "s16_all=[]\n",
    "s32_all=[]\n",
    "for i in tqdm(range(1, 27)):\n",
    "    s16, s32= average_per_person(f\"VN00{i}\")\n",
    "    s16_all.append(s16)\n",
    "    s32_all.append(s32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1ec7b4a-4a98-448e-8050-9cc3ebc962ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "s16=np.array(s16_all)\n",
    "s32=np.array(s32_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f049c6a-3248-4024-b6a0-9db3e303854a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 3, 28, 502)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "079c9501-5f78-439d-b35d-dc98cd83b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"S32.npy\", s32)\n",
    "np.save(\"S16.npy\", s16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c4b999c-9c72-465a-990d-1348fd4c53da",
   "metadata": {},
   "outputs": [],
   "source": [
    "s32=np.load(\"S32.npy\")\n",
    "s16=np.load(\"S16.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc799182-becb-4d0c-82a4-24caef98f77c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2nd order isometric calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d405087e-14fa-4316-842c-40950566a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s16=s16.reshape(26, 3, 28*502)\n",
    "s32=s32.reshape(26, 3, 28*502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34c18edb-4096-453c-921c-9135a860cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "85f3af91-4f8d-4141-a836-080679058111",
   "metadata": {},
   "outputs": [],
   "source": [
    "s16_pca=PCA(n_components=28)\n",
    "s16_comp=s16_pca.fit_transform(s16[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9f24d6f-a733-40f9-ba8f-cc12134c8cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s16_comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd1a4556-db75-4f32-8b5e-a2de7da0a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s32_pca=PCA(n_components=78)\n",
    "s32_comp=s32_pca.fit_transform(s32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1797b652-f1fb-4e03-a0db-53f86aeb55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s16_comp=s16_comp.reshape(78,1,78)\n",
    "s32_comp=s32_comp.reshape(78,1,78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9945a2c-3c67-4893-8926-2951d1a88347",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs=np.concatenate((s16_comp, s32_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81735868-bbc8-403d-8caa-140c4d84fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys=np.array([0]*78 + [1]*78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0a01932-7a25-4346-85f4-ef6a8e3fde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=met.LinearMetric(alpha=0,center_columns=False, score_method=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83927456-0dab-4bca-b319-fc4b3516a9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelizing 12090 distance calculations with 40 processes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing distances: 100%|██████████| 12090/12090 [00:56<00:00, 215.08it/s]\n"
     ]
    }
   ],
   "source": [
    "dist_matrix, _ = lm.pairwise_distances(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de94a32f-2741-49d3-9583-63c626956037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58225cee-c974-4327-976a-248a377b8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "mds=MDS(n_components=2,dissimilarity=\"precomputed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7df92179-504e-4562-a630-e49686032b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pb2276/.conda/envs/gpu/lib/python3.10/site-packages/sklearn/manifold/_mds.py:298: FutureWarning: The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "points=mds.fit_transform(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d3feb-46dd-46f0-a9b7-290778504c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(points[:,0], points[:,1],c=Ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df363f36-6b4d-483e-b2dd-b0ac579cdeea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Custom similarity loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bff2deca-edb3-441c-baa0-15ecde767c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "from typing import Literal, Tuple, Optional, List\n",
    "\n",
    "\n",
    "class LinearMeasure(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 alpha=1, center_columns=True, dim_matching='zero_pad', svd_grad=True, reduction='mean', no_svd=True):\n",
    "        super(LinearMeasure, self).__init__()\n",
    "        self.register_buffer('alpha', torch.tensor(alpha))\n",
    "        assert dim_matching in [None, 'none', 'zero_pad', 'pca']\n",
    "        self.dim_matching = dim_matching\n",
    "        self.center_columns = center_columns\n",
    "        self.svd_grad = svd_grad\n",
    "        self.reduction = reduction\n",
    "        self.no_svd=no_svd        \n",
    "\n",
    "    \n",
    "    def partial_fit(self, X: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"Computes the mean centered columns. Can be replaced later by whitening transform for linear invarariances.\"\"\"\n",
    "        if self.center_columns:\n",
    "            mx = torch.mean(X, dim=1, keepdim=True)\n",
    "        else:\n",
    "            mx = torch.zeros(X.shape[2], dtype=X.dtype, device=X.device)\n",
    "        wx = X - mx\n",
    "        \n",
    "        return mx, wx\n",
    "\n",
    "    def fit(self, X: Tensor, Y: Tensor) -> Tuple[Tuple[Tensor, Tensor], Tuple[Tensor, Tensor]]:\n",
    "        mx, wx = self.partial_fit(X)\n",
    "        my, wy = self.partial_fit(Y)            \n",
    "\n",
    "        if self.svd_grad:\n",
    "            wxy = torch.bmm(wx.transpose(1, 2), wy)\n",
    "            U, _, Vt = torch.linalg.svd(wxy)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                wxy = torch.bmm(wx.transpose(1, 2), wy)\n",
    "                U, _, Vt = torch.linalg.svd(wxy)\n",
    "        wx = U\n",
    "        wy = Vt.transpose(1, 2)\n",
    "        return (mx, wx), (my, wy)\n",
    "\n",
    "    def project(self, X: Tensor, m: Tensor, w: Tensor):\n",
    "        if self.center_columns:\n",
    "            return torch.bmm((X - m), w)\n",
    "        else:\n",
    "            return torch.bmm(X, w)\n",
    "\n",
    "    def forward(self, X: Tensor, Y: Tensor):\n",
    "        if X.shape[:-1] != Y.shape[:-1] or X.ndim != 3 or Y.ndim != 3:\n",
    "            raise ValueError('Expected 3D input matrices to much in all dimensions but last.'\n",
    "                             f'But got {X.shape} and {Y.shape} instead.')\n",
    "\n",
    "        if X.shape[-1] != Y.shape[-1]:\n",
    "            if self.dim_matching is None or self.dim_matching == 'none':\n",
    "                raise ValueError(f'Expected same dimension matrices got instead {X.shape} and {Y.shape}. '\n",
    "                                 f'Set dim_matching or change matrix dimensions.')\n",
    "            elif self.dim_matching == 'zero_pad':\n",
    "                size_diff = Y.shape[-1] - X.shape[-1]\n",
    "                if size_diff < 0:\n",
    "                    raise ValueError(f'With `zero_pad` dimension matching expected X dimension to be smaller then Y. '\n",
    "                                     f'But got {X.shape} and {Y.shape} instead.')\n",
    "                X = pad(X, (0, size_diff))\n",
    "            elif self.dim_matching == 'pca':\n",
    "                raise NotImplementedError\n",
    "            else:\n",
    "                raise ValueError(f'Unrecognized dimension matching {self.reduction}')\n",
    "        \n",
    "        if self.no_svd and X.shape[1]==1:\n",
    "            mx, wx = self.partial_fit(X)\n",
    "            my, wy = self.partial_fit(Y)\n",
    "\n",
    "            x_norm=torch.linalg.norm(wx, dim=(1,2))\n",
    "            y_norm=torch.linalg.norm(wy, dim=(1,2))\n",
    "\n",
    "            norms= torch.sqrt( x_norm**2 + y_norm **2 - 2*(x_norm *y_norm))\n",
    "\n",
    "        else:\n",
    "            X_params, Y_params = self.fit(X, Y)\n",
    "            norms = torch.linalg.norm(self.project(X, *X_params) - self.project(Y, *Y_params), ord=\"fro\", dim=(1, 2))\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return norms.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return norms.sum()\n",
    "        elif self.reduction == 'none' or self.reduction is None:\n",
    "            return norms\n",
    "        else:\n",
    "            raise ValueError(f'Unrecognized reduction {self.reduction}')\n",
    "\n",
    "\n",
    "class EnergyMetric(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_iter=100, tol=1e-6, dim_matching='zero_pad', reduction='mean'):\n",
    "        super(EnergyMetric,self).__init__()\n",
    "        self.n_iter=n_iter\n",
    "        self.tol=torch.tensor(tol)\n",
    "        assert dim_matching in [None, 'none', 'zero_pad', 'pca']\n",
    "        self.dim_matching = dim_matching\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def fit(self, X: torch.Tensor, Y:torch.Tensor):\n",
    "\n",
    "        n_x=X.shape[2]\n",
    "        n_y=Y.shape[2]\n",
    "        \n",
    "        X=X.repeat_interleave(n_y, dim=2).flatten(start_dim=1, end_dim=2)\n",
    "        Y=Y.tile(dims=(1, 1, n_x, 1)).flatten(start_dim=1, end_dim=2)\n",
    "\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            raise ValueError(f\"After permutation got {X.shape} and {Y.shape}\")\n",
    "        \n",
    "        w=torch.ones(X.shape[0], X.shape[1])\n",
    "        \n",
    "        batch_loss=[torch.mean(torch.linalg.norm(X-Y, dim=-1), dim =-1)]\n",
    "        for i in range(self.n_iter):\n",
    "            T=self.get_orth_matrix(w[:,:, None] *X, w[:, : , None]*Y)\n",
    "            iter_result=torch.linalg.norm(X-torch.bmm(Y, T),dim=-1)\n",
    "            batch_loss.append(torch.mean(iter_result, dim=-1))\n",
    "            w=1/torch.maximum(torch.sqrt(iter_result), self.tol)\n",
    "\n",
    "        return w, T, batch_loss, X, Y\n",
    "        \n",
    "    def get_orth_matrix(self, X:torch.Tensor , Y:torch.Tensor):\n",
    "        U, _, Vt= torch.linalg.svd(torch.bmm(X.transpose(1,2), Y))\n",
    "        return torch.bmm(Vt.transpose(1,2) , U.transpose(1,2))\n",
    "\n",
    "    def get_dist_energy(self,X:torch.Tensor): \n",
    "        n=X.shape[2]\n",
    "        combs = torch.combinations(torch.arange(n))\n",
    "        X1= torch.flatten(X[:, :, combs[:, 0], :], start_dim=1, end_dim=2)\n",
    "        X2=torch.flatten(X[:, :, combs[:, 1], :], start_dim=1, end_dim=2)\n",
    "        \n",
    "        return torch.mean(torch.linalg.norm(X2-X1, dim=-1), dim=-1)\n",
    "        \n",
    "        \n",
    "    def forward(self,X: torch.Tensor , Y:torch.Tensor ):\n",
    "\n",
    "        \"\"\"Expected tensors to be of the form batch x class x repeats x activations\"\"\"\n",
    "        \n",
    "        if X.shape[:-2] != Y.shape[:-2] or X.ndim != 4 or Y.ndim != 4:\n",
    "            raise ValueError('Expected 4D input matrices to much in all dimensions but last two.'\n",
    "                             f'But got {X.shape} and {Y.shape} instead.')\n",
    "\n",
    "        if X.shape[-1] != Y.shape[-1]:\n",
    "            if self.dim_matching is None or self.dim_matching == 'none':\n",
    "                raise ValueError(f'Expected same dimension matrices got instead {X.shape} and {Y.shape}. '\n",
    "                                 f'Set dim_matching or change matrix dimensions.')\n",
    "            elif self.dim_matching == 'zero_pad':\n",
    "                size_diff = Y.shape[-1] - X.shape[-1]\n",
    "                if size_diff < 0:\n",
    "                    raise ValueError(f'With `zero_pad` dimension matching expected X dimension to be smaller then Y. '\n",
    "                                     f'But got {X.shape} and {Y.shape} instead.')\n",
    "                X = pad(X, (0, size_diff))\n",
    "            elif self.dim_matching == 'pca':\n",
    "                raise NotImplementedError\n",
    "            else:\n",
    "                raise ValueError(f'Unrecognized dimension matching {self.reduction}')\n",
    "                \n",
    "        #return self.fit(X,Y)\n",
    "        w,T,fit_loss, X_prod, Y_prod= self.fit(X,Y)\n",
    "        \n",
    "        e_xx=self.get_dist_energy(X)\n",
    "        e_yy=self.get_dist_energy(Y)\n",
    "        Y_proj=torch.bmm(Y_prod, T)\n",
    "        e_xy=torch.mean(torch.linalg.norm(X_prod-Y_proj, dim=-1),dim=-1)\n",
    "\n",
    "        norms= torch.sqrt(torch.nn.functional.relu(e_xy-0.5*(e_xx+e_yy)))\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return norms.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return norms.sum()\n",
    "        elif self.reduction == 'none' or self.reduction is None:\n",
    "            return norms\n",
    "        else:\n",
    "            raise ValueError(f'Unrecognized reduction {self.reduction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87d5dfaa-6198-4833-a662-3ccbf2fdef4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 3, 28, 502)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f310264-90ff-4444-9f9d-8630a2af2792",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(1, 26*3, 28*502).to(device)\n",
    "y=torch.rand(1, 26*3, 28*502).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0916f235-21f4-4fcd-bffb-2ed9321e3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=LinearMeasure(svd_grad=False)\n",
    "opt=torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbe127-9dda-4895-95e5-9f2399645cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s16_t=torch.tensor(s16_across_trials, dtype=torch.float32).to(device).requires_grad_(True)\n",
    "s32_t=torch.tensor(s32_across_trials, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a44992-51d8-4ec3-8304-b201c67ad997",
   "metadata": {},
   "outputs": [],
   "source": [
    "s16_lower_dim=model(s16_t)\n",
    "s32_lower_dim=model(s32_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946e26b-b16e-4dc0-ad95-f966366491eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=lm(s16_t,s32_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef757183-f693-4c7b-bd3a-ef2c4883a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_batch=[]\n",
    "test_loss_batch=[]\n",
    "for epochs in range(100):\n",
    "    with torch.no_grad():\n",
    "        test_out=model(s16_t)\n",
    "        test_loss=crit(test_out[:,0], y_test_gpu)\n",
    "        test_loss_batch.append(test_loss.item())   \n",
    "        \n",
    "    opt.zero_grad()\n",
    "    out=model(x_batch)\n",
    "    loss=crit(out[:,0], y_batch)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    train_loss_batch.append(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
